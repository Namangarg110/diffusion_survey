In the exploration of video diffusion models, a broad spectrum of video analysis techniques is examined, encompassing the generation, modification, and interpretation of video content. These methods frequently adopt diffusion generation approaches or capitalize on the advanced generative capacities of diffusion models for subsequent applications. This survey prioritizes areas such as the creation of videos from text \cite{Singer2023MakeAV, Ho2022ImagenVH, Xing2023SimdaSA}, generating videos without predefined conditions \cite{Ho2022VideoDM, Hu2023LamdLV, Mei2023VidmVI}, and video modification guided by text descriptions \cite{Wu2023TuneAV, Esser2023StructureAC, Molad2023DreamixVD}, among others.

\subsection{Creation of Videos from Text}
Creation of Videos from Text is concerned with the automated transformation of textual narratives into videos. This requires the interpretation and conversion of text-described scenes, objects, and actions into a sequence of frames that visually cohere, thus yielding a video that is consistent both logically and visually. This technology finds application across various domains, including the automated production of films \cite{Zhu2023MoviefactoryAM}, animations \cite{He2023AnimateAS, Guo2023AnimatediffAY}, virtual reality, and educational materials \cite{Yang2023ProbabilisticAO}.

\subsection{Video Generation Without Predefined Conditions}
Video Generation Without Predefined Conditions describes the challenge of producing a continuous, visually coherent series of video frames from either stochastic noise or a predetermined starting point, with no reliance on specific input conditions. This mode of video generation distinguishes itself by not necessitating any external data or conditions \cite{Ho2022VideoDM, Hu2023LamdLV, Mei2023VidmVI}, thus challenging the generative model to independently learn the necessary temporal dynamics and visual elements for realistic and varied video content. This underscores the model's ability to understand content from unlabelled data and its potential for showcasing diversity.

\subsection{Text-driven Video Modification}
Text-driven Video Modification involves leveraging textual instructions to direct video content alterations. Through this method, a textual input specifies the desired video modifications, and the system employs this description to identify and implement changes based on the text-identified objects, actions, or scenes. This approach enhances editing efficiency and intuitiveness by enabling the use of natural language to describe edits \cite{Wu2023TuneAV, Esser2023StructureAC, Molad2023DreamixVD}, potentially diminishing the reliance on meticulous, frame-by-frame adjustments.